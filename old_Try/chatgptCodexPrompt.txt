Du bist ein AI Agent developer. Du sollst ein system Entwikeln welches mit Ollama und Python ein llm einbindet und code ausführen kann.
Dein Ziel: Schreibe ein sauber aufgeteiltes pytrhon projekt mit mehreren separaten files, die eine ollama schnittstelle mittels einem lokalen llm baut.
der gewünschte Codeablauf wäre (Baue sicherheits und robuste Codezeilen ein um das scriptz robust zu gestalten): Der User gibt eine Aufgabe. Das Erste llm soll diese
Aufgabe in ein Plan umwandeln (dieser 1.Prompt und Plan sollen gespeichert werden). Schreibe auch ein separates file für die weweiligen systemprompts. 
der Plan soll klar als Liste widergegeben werden, dass ein weiteres llm mit einem stück des plans + die aufgabenstellung genau (vom planer). der Planer soll für weitere Agenten je ein prompt eines 
speziefischen Problem oder Arbeit erstellen. er Soll nur im Json format antworten. Im json soll folgendes mitgegeben werden : 1. rückfragen : Bool, Frage: "Frage wenn etwas unklar ist und der rest soll leer sein.(bei Rückfragen soll das llm bei der Antwort folgendes beigefügt werden: den ursprünglicher die frage und natürlich die antwort, es soll so lange alle infos erhalten bis der plan und die prompts fürd die weiteren agenten bereitgestellt werden können.)
2. "Prompt des Users : "Hier eine detailierte zusammenfassung des Userprompts", plan vom planer für den agenten (spezifischer aufgaben beschrieb mit wichtigen infos zum zusammenfügen.) hier soll es weiter laufen bis alle aufgaben einen prompt mit dessen infos hat. 
Frage auch hier genau nach, wie der genaue ablauf erstellt werden soll. baue das skript robust und prompte das modell nochmals wenn es fehler bei den nachfolgende code generiert. Anhand des bereits existoierendem Code kannst du dich grob orientieren.
Leider ist in diesem Fall, oft das problem, dass das json nicht richtig extrahiert werden kann. probier es zuerst so wie es ist und mache es noch robuster wenn möglich. baue eine text analyse die die genauen keys vom dict probiert zu extrahieren und so kann das json evt auch genutzt werden. 


JSon Prompt:
für das extrahieren von json dateien oder halt einzelne infomationen soll wie folgt ablaufen:
Zuerst soll genau wie schon vorhanden die beiden """ oder einzelnen extrahiert werden. Dann das json elemenzt. wenn dann nicht komplett soll einmal eine geschweifte klammer am schluss angefügt werdne und nochmals probiert.
wenn wieder nicht, sollen alle absätze im text entfernt werden, dann nochmals probieren, wenn wieder nicht alle absätze entfernen und eine klammer anfügen. wenn es dann immernoch nicht funktioniert zurück prompten.

Neure Prompt für ausbau.
Analysiere dieses Projekt komplett. Nutze die einzelnen Komponenten die Sinnvol sind.
Baue jedoch das ganze neu. Es sollen mehrer weitere unterschritte zwischendurch erstellt werden. Der start
sieht wigentlich ähnlich aus, jedoch soll einfach vom Planer ein Plan gemacht werden ohne nummeriereung nur in einem json mit dem key plan und dazu eine Liste mit strings.
Der Userprompt sowie der Plan werden zwischengespeichert als json und auch den weiteren Modellen mit genauer erklärung was das ist mitgegeben. nachdem ein Plan erstellt wurde, soll das nächste Modell den Prompt für den nächsten 
Schritt des Planes erstellen. nach dem Prompt soll das ausführende Modell an die Arbeit. Es soll wieder alle Infos: Userprompt: Plan: Direkter Prompt erhalten, tools infos, die ganze Ordnerstruktur mit filenamen. und mittels diesen Infos, soll zuerst geschaut werden, welche tools bereits existieren und sonst soll es die benötigten Tools schreiben die benötigt werden.
Diese Aufgliederung soll genau im systemprompt dargestellt werden, damit die Funktionen auch richtig genutzt werden können. Schaue, dass wenn der ausführende mehr infos benötigt indem es daten lesen soll das er sich selbst schnell füttern kann. anhand des strukturiertem json output (
wie zum Beispiel: "fast_infos": True, "use_tool": "name vom Tool" und alles andere kann leer sein). 
Wenn das Tool richtig funktioniert und funktioniert hat, soll erst weiter gearbeitet werden. bei Fehler soll der Traceback oder die Fehlerangabe mit allen restrlichen Infos dieses Schrittes neu gepromptet werden.
für den funktionalitätstest, soll die funktion ausgeführt werden. es kann ein fast_tool.py erstellt werden die immer vom hauptcyrcle nach einem abgeschlossener antwort ausgeführt wird, wenn das model eine Funktion im json zurückgibt. es soll im json eine eigene key für das angegeben werden. Diese Funktion 
kann dann laufend überprüft werden, ob sie funktioniert unnd auch diekt angepasst wenn etwas nicht klappt.
Danach soll der kontrolleur kommen und schauen, ob die vom toolersteller und funktionen wirklich die dateien so angepasst haben, das sie auch stimmen im code. 
also wenn die Funktion funktioniert, soll sichergestellt werden, dass diese auch am richtigen platz danach ist. das letzte Modell soll alle infos die die andern haben auch mitbekommen für die kontrolle.


Der aufbau und Architektur dieses Projekts soll sauber und schön unterteilt dargestellt werden.
Das Projekt soll später sich selber umprogramieren/erweitern können (zugriffe auf eigenen Code soll gewährleistet sein). Es soll aber auch die Möglichkeit haben unabhängige Projekte zu erstellen / erweitern, 
Schreibe den ganzen Code sehr robust und greife viele Möglichkeiten ab die zu Fehler führen könnten. Ergänze jegliche Systemprompts oder erneuere sie wenn nötig und baue das ganze Projekt nach den neuen Vorsetllunge um.
